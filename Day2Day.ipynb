{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "import pandas as pd\n",
    "from random import randint, choice, uniform\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Initialize Faker\n",
    "fake = Faker()\n",
    "\n",
    "# Generate a list of trader IDs and companies\n",
    "trader_ids = [fake.random_number(digits=5) for _ in range(100)]  # 100 unique trader IDs\n",
    "companies = [fake.company() for _ in range(10)]  # 100 unique companies\n",
    "\n",
    "# Define a list of currency pairs and corresponding spot rate range\n",
    "currency_data = {\n",
    "    'EUR/USD': {'spot_rate_range': (1.1, 1.2)},\n",
    "    'USD/JPY': {'spot_rate_range': (105, 115)},\n",
    "    'GBP/USD': {'spot_rate_range': (1.3, 1.4)},\n",
    "    'USD/CHF': {'spot_rate_range': (0.9, 1.0)},\n",
    "    'USD/CAD': {'spot_rate_range': (1.2, 1.3)},\n",
    "    'AUD/USD': {'spot_rate_range': (0.7, 0.8)},\n",
    "    'NZD/USD': {'spot_rate_range': (0.6, 0.7)},\n",
    "}\n",
    "\n",
    "# Define the structure of your transaction data\n",
    "def generate_transaction():\n",
    "    currency_pair = choice(list(currency_data.keys()))\n",
    "    buy_currency, sell_currency = currency_pair.split('/')\n",
    "    rate_data = currency_data[currency_pair]\n",
    "    buy_sell_indicator = choice(['Buy', 'Sell'])\n",
    "    quantity = randint(1, 10000) * 10000\n",
    "    spot_rate = round(fake.pyfloat(right_digits=4, positive=True, min_value=rate_data['spot_rate_range'][0], max_value=rate_data['spot_rate_range'][1]), 4)  # generating a spot rate within the range\n",
    "    # calculate a forward rate within 1% of the spot rate\n",
    "    forward_rate = round(spot_rate * uniform(0.99, 1.01), 4)\n",
    "    return {\n",
    "        'TransactionID': fake.unique.random_number(digits=8),\n",
    "        'TradingDate': fake.date_between(start_date='-1y', end_date='today'),\n",
    "        'MaturityDate': fake.date_between(start_date='today', end_date='+1y'),\n",
    "        'ExecutionTime': (datetime.now()-timedelta(seconds=randint(1,86400))).strftime('%H:%M:%S'),\n",
    "        'InstrumentID': fake.random_number(digits=12),\n",
    "        'TraderID': choice(trader_ids),  # select a trader ID from the list\n",
    "        'BuyCurrency': buy_currency,\n",
    "        'SellCurrency': sell_currency,\n",
    "        'SpotRate': spot_rate,\n",
    "        'ForwardRate': forward_rate,\n",
    "        'BuySellIndicator': buy_sell_indicator,\n",
    "        'BuyNotional': round(quantity, 2),\n",
    "        'SellNotional': round(quantity * spot_rate, 2),\n",
    "        'Counterparty': choice(companies)  # select a company from the list\n",
    "    }\n",
    "\n",
    "# Generate n transactions\n",
    "def generate_transactions(n=100):\n",
    "    return [generate_transaction() for _ in range(n)]\n",
    "\n",
    "# Usage\n",
    "data = generate_transactions(1000)  # generate 10,000 transactions\n",
    "transactions_df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "transactions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Assume transaction_df is already provided\n",
    "# Define a time grid\n",
    "time_grid = list(range(1, 15)) + list(range(14, 91, 7)) + list(range(90, 366, 30))\n",
    "\n",
    "# Mock functions to fetch volatility and correlation matrix\n",
    "def fetch_vol_and_correlation(alternative=False):\n",
    "    if alternative == False:\n",
    "        volatilities_usd = {\n",
    "            'EUR': 0.1,\n",
    "            'JPY': 0.15,\n",
    "            'GBP': 0.12,\n",
    "            'CHF': 0.1,\n",
    "            'CAD': 0.13,\n",
    "            'AUD': 0.14,\n",
    "            'NZD': 0.15\n",
    "        }\n",
    "    else:\n",
    "        volatilities_usd = {\n",
    "            'EUR': 0.12,\n",
    "            'JPY': 0.15,\n",
    "            'GBP': 0.12,\n",
    "            'CHF': 0.2,\n",
    "            'CAD': 0.16,\n",
    "            'AUD': 0.14,\n",
    "            'NZD': 0.2\n",
    "        }\n",
    "\n",
    "    correlation_matrix_usd = np.array([\n",
    "        [1.0, 0.3, 0.2, 0.1, 0.1, 0.2, 0.1],\n",
    "        [0.3, 1.0, 0.4, 0.2, 0.2, 0.1, 0.2],\n",
    "        [0.2, 0.4, 1.0, 0.3, 0.3, 0.2, 0.3],\n",
    "        [0.1, 0.2, 0.3, 1.0, 0.4, 0.3, 0.2],\n",
    "        [0.1, 0.2, 0.3, 0.4, 1.0, 0.2, 0.1],\n",
    "        [0.2, 0.1, 0.2, 0.3, 0.2, 1.0, 0.4],\n",
    "        [0.1, 0.2, 0.3, 0.2, 0.1, 0.4, 1.0]\n",
    "    ])\n",
    "    return volatilities_usd, correlation_matrix_usd\n",
    "\n",
    "# Functions to calculate PFE\n",
    "def convert_to_usd(notional, currency, spot_rate):\n",
    "    if currency == 'USD':\n",
    "        return notional\n",
    "    return notional / spot_rate\n",
    "\n",
    "# Create an exposure vector\n",
    "def create_exposure_vector(buy_currency, sell_currency, buy_notional_usd, sell_notional_usd, volatilities_usd):\n",
    "    currencies = list(volatilities_usd.keys())\n",
    "    exposures = np.zeros(len(currencies))\n",
    "\n",
    "    for i, currency in enumerate(currencies):\n",
    "        if currency == buy_currency:\n",
    "            exposures[i] += buy_notional_usd\n",
    "        if currency == sell_currency:\n",
    "            exposures[i] -= sell_notional_usd\n",
    "    return exposures\n",
    "\n",
    "# Create an exposure vector\n",
    "def create_aggregated_exposure_vector(aggregated_exposures, volatilities_usd):\n",
    "    currencies = list(volatilities_usd.keys())\n",
    "    exposures = np.zeros(len(currencies))\n",
    "\n",
    "    for currency, notional in aggregated_exposures.items():\n",
    "        if currency in currencies:\n",
    "            index = currencies.index(currency)\n",
    "            exposures[index] = notional\n",
    "    return exposures\n",
    "\n",
    "\n",
    "def calculate_pfe_with_cov_matrix(exposures, days, cov_matrix, confidence_level=0.99):\n",
    "    # ensure that the length of exposure is equal to a side of the covariance matrix\n",
    "    if len(exposures) != cov_matrix.shape[0]:\n",
    "        raise ValueError(\"Length of exposures should match the covariance matrix\")\n",
    "\n",
    "    exposures_vector = np.array(exposures)\n",
    "    # adjust the covariance matrix for the number of days, the covariance matrix is assumed to be annualized\n",
    "    cov_matrix = cov_matrix * days / 365\n",
    "\n",
    "    variance = exposures_vector.T @ cov_matrix @ exposures_vector\n",
    "    stddev = np.sqrt(variance)\n",
    "    z_score = norm.ppf(confidence_level)\n",
    "\n",
    "    pfe = stddev * z_score\n",
    "    return pfe\n",
    "\n",
    "\n",
    "def calculate_pfe_for_trade(row, volatilities, cov_matrix, time_grid, mpor):\n",
    "    pfe_results = {}\n",
    "    buy_currency = row['BuyCurrency']\n",
    "    sell_currency = row['SellCurrency']\n",
    "    spot_rate = row['SpotRate']\n",
    "    buy_notional_usd = convert_to_usd(row['BuyNotional'], buy_currency, spot_rate)\n",
    "    sell_notional_usd = convert_to_usd(row['SellNotional'], sell_currency, spot_rate)\n",
    "\n",
    "    for days in time_grid:\n",
    "        if row['MaturityDate'] < row['TradingDate'] + timedelta(days=days):\n",
    "            continue  # Exclude matured trades\n",
    "\n",
    "        exposures = create_exposure_vector(buy_currency, sell_currency, buy_notional_usd, sell_notional_usd, volatilities)\n",
    "\n",
    "        standalone_pfe = calculate_pfe_with_cov_matrix(exposures, days, cov_matrix, confidence_level=0.99)\n",
    "        collateralized_pfe = calculate_pfe_with_cov_matrix(exposures, mpor, cov_matrix, confidence_level=0.99)\n",
    "\n",
    "        pfe_results[days] = {\n",
    "            'Standalone': standalone_pfe,\n",
    "            'Collateralized': collateralized_pfe\n",
    "        }\n",
    "\n",
    "    return pfe_results\n",
    "\n",
    "def aggregate_exposures_by_counterparty(transactions_df):\n",
    "    counterparty_exposures = {}\n",
    "\n",
    "    for _, row in transactions_df.iterrows():\n",
    "        buy_currency = row['BuyCurrency']\n",
    "        sell_currency = row['SellCurrency']\n",
    "        spot_rate = row['SpotRate']\n",
    "        buy_notional_usd = convert_to_usd(row['BuyNotional'], buy_currency, spot_rate)\n",
    "        sell_notional_usd = convert_to_usd(row['SellNotional'], sell_currency, spot_rate)\n",
    "        counterparty = row['Counterparty']\n",
    "\n",
    "        if counterparty not in counterparty_exposures:\n",
    "            counterparty_exposures[counterparty] = {}\n",
    "\n",
    "        if buy_currency not in counterparty_exposures[counterparty]:\n",
    "            counterparty_exposures[counterparty][buy_currency] = 0\n",
    "        if sell_currency not in counterparty_exposures[counterparty]:\n",
    "            counterparty_exposures[counterparty][sell_currency] = 0\n",
    "\n",
    "        counterparty_exposures[counterparty][buy_currency] += buy_notional_usd\n",
    "        counterparty_exposures[counterparty][sell_currency] -= sell_notional_usd\n",
    "\n",
    "    return counterparty_exposures\n",
    "\n",
    "def calculate_pfe_for_counterparties(counterparty_exposures, volatilities, cov_matrix, time_grid, mpor):\n",
    "    counterparty_pfe = {}\n",
    "\n",
    "    for counterparty, exposures in counterparty_exposures.items():\n",
    "        exposure_vector = create_aggregated_exposure_vector(exposures, volatilities)\n",
    "        pfe_results = {}\n",
    "\n",
    "        for days in time_grid:\n",
    "            standalone_pfe = calculate_pfe_with_cov_matrix(exposure_vector, days, cov_matrix, confidence_level=0.99)\n",
    "            collateralized_pfe = calculate_pfe_with_cov_matrix(exposure_vector, mpor, cov_matrix, confidence_level=0.99)\n",
    "\n",
    "            pfe_results[days] = {\n",
    "                'Standalone': standalone_pfe,\n",
    "                'Collateralized': collateralized_pfe\n",
    "            }\n",
    "\n",
    "        counterparty_pfe[counterparty] = pfe_results\n",
    "\n",
    "    return counterparty_pfe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Margin period of risk (MPOR) in days\n",
    "mpor = 10\n",
    "\n",
    "# Fetch volatilities and correlation matrix\n",
    "volatilities_usd, correlation_matrix_usd = fetch_vol_and_correlation()\n",
    "\n",
    "# Calculate variance-covariance matrix for USD pairs\n",
    "volatility_vector = np.array(list(volatilities_usd.values()))\n",
    "cov_matrix_usd = np.dot(volatility_vector[:, None], volatility_vector[None, :]) * correlation_matrix_usd\n",
    "\n",
    "# Aggregate exposures by counterparty\n",
    "counterparty_exposures = aggregate_exposures_by_counterparty(transactions_df)\n",
    "\n",
    "# Calculate PFE for each counterparty\n",
    "counterparty_pfe = calculate_pfe_for_counterparties(counterparty_exposures, volatilities_usd, cov_matrix_usd, time_grid, mpor)\n",
    "\n",
    "# Convert counterparty PFE to DataFrame for display\n",
    "counterparty_pfe_df = []\n",
    "for counterparty, pfe_data in counterparty_pfe.items():\n",
    "    for days, pfes in pfe_data.items():\n",
    "        row = {'Counterparty': counterparty, 'Days': days, 'Standalone_PFE': pfes['Standalone'], 'Collateralized_PFE': pfes['Collateralized']}\n",
    "        counterparty_pfe_df.append(row)\n",
    "\n",
    "counterparty_pfe_df = pd.DataFrame(counterparty_pfe_df)\n",
    "\n",
    "# Go thru each transaction_df and calculate PFE as a full term structure in a new dataframe, with the trade id as the key\n",
    "pfe_results = []\n",
    "for idx, row in transactions_df.iterrows():\n",
    "    trade_pfe = calculate_pfe_for_trade(row, volatilities_usd, cov_matrix_usd, time_grid, mpor)\n",
    "    # Append the trade ID and cpty to pfe_results to the trade_pfe, no need to flatten the dictionary\n",
    "    pfe_results.append(\n",
    "        {\n",
    "            'TransactionID': row['TransactionID'],\n",
    "            'Counterparty': row['Counterparty'],\n",
    "            'BuyCurrency': row['BuyCurrency'],\n",
    "            'SellCurrency': row['SellCurrency'],\n",
    "            'MaturityDate': row['MaturityDate'],\n",
    "            'PFE': trade_pfe})\n",
    "\n",
    "# flatten pfe_results and PFE with the days as a new column to a dataframe\n",
    "pfe_results_df = []\n",
    "for row in pfe_results:\n",
    "    for days, pfe in row['PFE'].items():\n",
    "        pfe_results_df.append(\n",
    "            {'TransactionID': row['TransactionID'],\n",
    "             'Counterparty': row['Counterparty'],\n",
    "             'BuyCurrency': row['BuyCurrency'],\n",
    "             'SellCurrency': row['SellCurrency'],\n",
    "             'MaturityDate': row['MaturityDate'],\n",
    "             'Days': days,\n",
    "             'Standalone_PFE': pfe['Standalone'],\n",
    "             'Collateralized_PFE': pfe['Collateralized']})\n",
    "\n",
    "pfe_results_df = pd.DataFrame(pfe_results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Next day\n",
    "\n",
    "# Fetch volatilities and correlation matrix\n",
    "volatilities_usd_d1, correlation_matrix_usd_d1 = fetch_vol_and_correlation(alternative=True)\n",
    "\n",
    "# Calculate variance-covariance matrix for USD pairs\n",
    "volatility_vector_d1 = np.array(list(volatilities_usd_d1.values()))\n",
    "cov_matrix_usd_d1 = np.dot(volatility_vector_d1[:, None], volatility_vector_d1[None, :]) * correlation_matrix_usd_d1\n",
    "\n",
    "# Aggregate exposures by counterparty\n",
    "counterparty_exposures_d1 = aggregate_exposures_by_counterparty(transactions_df)\n",
    "\n",
    "# Calculate PFE for each counterparty\n",
    "counterparty_pfe_d1 = calculate_pfe_for_counterparties(counterparty_exposures_d1, volatilities_usd_d1, cov_matrix_usd_d1, time_grid, mpor)\n",
    "\n",
    "# Convert counterparty PFE to DataFrame for display\n",
    "counterparty_pfe_d1_df = []\n",
    "for counterparty, pfe_data in counterparty_pfe_d1.items():\n",
    "    for days, pfes in pfe_data.items():\n",
    "        row = {'Counterparty': counterparty, 'Days': days, 'Standalone_PFE': pfes['Standalone'], 'Collateralized_PFE': pfes['Collateralized']}\n",
    "        counterparty_pfe_d1_df.append(row)\n",
    "\n",
    "counterparty_pfe_d1_df = pd.DataFrame(counterparty_pfe_d1_df)\n",
    "\n",
    "# Go thru each transaction_df and calculate PFE as a full term structure in a new dataframe, with the trade id as the key\n",
    "pfe_results_d1 = []\n",
    "for idx, row in transactions_df.iterrows():\n",
    "    trade_pfe = calculate_pfe_for_trade(row, volatilities_usd_d1, cov_matrix_usd_d1, time_grid, mpor)\n",
    "    # Append the trade ID and cpty to pfe_results to the trade_pfe, no need to flatten the dictionary\n",
    "    pfe_results_d1.append(\n",
    "        {\n",
    "            'TransactionID': row['TransactionID'],\n",
    "            'Counterparty': row['Counterparty'],\n",
    "            'BuyCurrency': row['BuyCurrency'],\n",
    "            'SellCurrency': row['SellCurrency'],\n",
    "            'MaturityDate': row['MaturityDate'],\n",
    "            'PFE': trade_pfe})\n",
    "\n",
    "# flatten pfe_results and PFE with the days as a new column to a dataframe\n",
    "pfe_results_d1_df = []\n",
    "for row in pfe_results_d1:\n",
    "    for days, pfe in row['PFE'].items():\n",
    "        pfe_results_d1_df.append(\n",
    "            {'TransactionID': row['TransactionID'],\n",
    "             'Counterparty': row['Counterparty'],\n",
    "             'BuyCurrency': row['BuyCurrency'],\n",
    "             'SellCurrency': row['SellCurrency'],\n",
    "             'MaturityDate': row['MaturityDate'],\n",
    "             'Days': days,\n",
    "             'Standalone_PFE': pfe['Standalone'],\n",
    "             'Collateralized_PFE': pfe['Collateralized']})\n",
    "\n",
    "pfe_results_d1_df = pd.DataFrame(pfe_results_d1_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor, export_text\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Assume pfe_results_df and pfe_results_d1_df are already provided\n",
    "\n",
    "# Perform an inner join on TransactionID and Days\n",
    "merged_df = pd.merge(pfe_results_df, pfe_results_d1_df, on=['TransactionID', 'Days'], suffixes=('_d0', '_d1'))\n",
    "\n",
    "# Calculate the differences\n",
    "merged_df['Standalone_PFE_Diff'] = merged_df['Standalone_PFE_d1'] - merged_df['Standalone_PFE_d0']\n",
    "merged_df['Collateralized_PFE_Diff'] = merged_df['Collateralized_PFE_d1'] - merged_df['Collateralized_PFE_d0']\n",
    "\n",
    "# Set a significant threshold based on 95th percentile of the differences\n",
    "\n",
    "# Standalone PFE Difference\n",
    "standalone_threshold = np.percentile(abs(merged_df['Standalone_PFE_Diff']), 95)\n",
    "\n",
    "# Collateralized PFE Difference\n",
    "collateralized_threshold = np.percentile(abs(merged_df['Collateralized_PFE_Diff']), 95)\n",
    "\n",
    "# Create binary labels\n",
    "merged_df['Standalone_Significant'] = (abs(merged_df['Standalone_PFE_Diff']) > standalone_threshold).astype(int)\n",
    "merged_df['Collateralized_Significant'] = (abs(merged_df['Collateralized_PFE_Diff']) > collateralized_threshold).astype(int)\n",
    "\n",
    "# One-hot encode categorical features\n",
    "categorical_features = ['BuyCurrency_d0', 'SellCurrency_d0']\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
    "encoded_features = onehot_encoder.fit_transform(merged_df[categorical_features])\n",
    "encoded_feature_names = onehot_encoder.get_feature_names_out(categorical_features)\n",
    "\n",
    "encoded_df = pd.DataFrame(encoded_features, columns=encoded_feature_names)\n",
    "\n",
    "# Combine all features\n",
    "final_features_df = pd.concat([merged_df[['Days']], encoded_df], axis=1)\n",
    "# Define features and target for standalone PFE difference\n",
    "X = final_features_df\n",
    "y_standalone = merged_df['Standalone_Significant']\n",
    "y_collateralized = merged_df['Collateralized_Significant']\n",
    "\n",
    "# Train a Decision Tree for Standalone PFE Difference\n",
    "tree_model_standalone = DecisionTreeRegressor(random_state=0, max_depth=5)\n",
    "param_grid = {'random_state': np.arange(10)}\n",
    "grid_search_standalone = GridSearchCV(tree_model_standalone, param_grid, cv=10, scoring='accuracy')\n",
    "grid_search_standalone.fit(X, y_standalone)\n",
    "\n",
    "# Get the best model\n",
    "best_tree_model_standalone = grid_search_standalone.best_estimator_\n",
    "best_tree_model_standalone.fit(X, y_standalone)\n",
    "\n",
    "# Export the tree as text for Standalone PFE Difference\n",
    "tree_rules_standalone = export_text(best_tree_model_standalone, feature_names=final_features_df.columns.to_list())\n",
    "\n",
    "text = ''\n",
    "text += 'Decision Tree Rules for Standalone PFE Difference:\\n'\n",
    "text += tree_rules_standalone\n",
    "\n",
    "# Train a Decision Tree for Collateralized PFE Difference\n",
    "tree_model_collateralized = DecisionTreeRegressor(random_state=0, max_depth=5)\n",
    "param_grid = {'random_state': np.arange(10)}\n",
    "grid_search_collateralized = GridSearchCV(tree_model_collateralized, param_grid, cv=10, scoring='accuracy')\n",
    "grid_search_collateralized.fit(X, y_collateralized)\n",
    "\n",
    "# Get the best model\n",
    "best_tree_model_collateralized = grid_search_collateralized.best_estimator_\n",
    "best_tree_model_collateralized.fit(X, y_collateralized)\n",
    "\n",
    "# Export the tree as text for Collateralized PFE Difference\n",
    "tree_rules_collateralized = export_text(best_tree_model_collateralized, feature_names=final_features_df.columns.to_list())\n",
    "\n",
    "text += '\\nDecision Tree Rules for Collateralized PFE Difference:\\n'\n",
    "text += tree_rules_collateralized\n",
    "\n",
    "# print volatility and correlation matrix to string, concatenate and with headlines explaining them\n",
    "volatilities_usd_text = 'Volatilities for USD pairs:\\n'\n",
    "volatilities_usd_text += str(volatilities_usd)\n",
    "volatilities_usd_text += '\\n\\n'\n",
    "\n",
    "correlation_matrix_usd_text = 'Correlation Matrix for USD pairs:\\n'\n",
    "correlation_matrix_usd_text += str(correlation_matrix_usd)\n",
    "correlation_matrix_usd_text += '\\n\\n'\n",
    "\n",
    "volatilities_usd_d1_text = 'Volatilities for USD pairs in d1:\\n'\n",
    "volatilities_usd_d1_text += str(volatilities_usd_d1)\n",
    "volatilities_usd_d1_text += '\\n\\n'\n",
    "\n",
    "correlation_matrix_usd_d1_text = 'Correlation Matrix for USD pairs in d1:\\n'\n",
    "correlation_matrix_usd_d1_text += str(correlation_matrix_usd_d1)\n",
    "correlation_matrix_usd_d1_text += '\\n\\n'\n",
    "\n",
    "# Combine all text\n",
    "market_data_text = volatilities_usd_text + correlation_matrix_usd_text + volatilities_usd_d1_text + correlation_matrix_usd_d1_text\n",
    "\n",
    "# Function to visualize a decision tree with improved readability\n",
    "def visualize_tree(model, feature_names, title):\n",
    "    plt.figure(figsize=(30, 15))  # Increase figure size for better readability\n",
    "    tree.plot_tree(model, feature_names=feature_names, filled=True, fontsize=10)  # Adjust font size\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Visualize the Standalone PFE Difference Decision Tree\n",
    "visualize_tree(best_tree_model_standalone, final_features_df.columns, \"Decision Tree for Standalone PFE Difference\")\n",
    "\n",
    "# Visualize the Collateralized PFE Difference Decision Tree\n",
    "visualize_tree(best_tree_model_collateralized, final_features_df.columns, \"Decision Tree for Collateralized PFE Difference\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "final_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(market_data_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You will be given a PFE difference tree for both collateralized and uncollateralized standalone trades between two days. \n",
    "Additionally, market data inputs such as volatility and spot rates for both days will be provided.\n",
    "Note that the columns with categorical features are one-hot encoded.\n",
    "Also the differences in PFE are calculated for each trade and the significant differences are identified based on a threshold, which is what the decision tree is trained on.\n",
    "When you see that the number of days are affecting the PFE, it is likely to be due to volatility and correlation changes.\n",
    "For FX trades that are uncollateralized, it is expected that the PFE will increase with number of days in the future, but that's not as expected for collateralized trades.\n",
    "\n",
    "Your task is to compare the differences between the two days, analyze the key factors driving the changes, and summarize your findings. Specifically, please:\n",
    "\n",
    "1. Identify the primary drivers for the differences in PFE. Note that many features are one-hot encoded, so you may need to interpret the rules accordingly.\n",
    "2. Explain how changes in market data (e.g., volatility, spot rates) are impacting the PFE calculations.\n",
    "3. Highlight any significant patterns or anomalies in the decision tree.\n",
    "4. Provide recommendations on what we should examine further based on your analysis. Note that we are only interested in the computational aspects of the analysis, not the business implications.\n",
    "\n",
    "Finally please provide an executive summary on the next steps and investigations that should be conducted based on your analysis.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Parse out the response\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
